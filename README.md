# ğŸŒŸ NLKI: Lightweight Natural Language Knowledge Integration Framework

[![Paper](https://img.shields.io/badge/Paper-EMNLP%20Findings%202025-blue)](https://arxiv.org/abs/2508.19724)  
[![Website](https://img.shields.io/badge/Project-Website-green)](https://beingdutta.github.io/NLKI-Project-Page-EMNLP-2025-Findings/)  

Official **codebase** for the EMNLP Findings 2025 paper:  
**â€œNLKI: A Lightweight Natural Language Knowledge Integration Framework for Improving Small VLMs in Commonsense VQA Tasksâ€**  

---

## ğŸ–¼ï¸ Overview
**NLKI** is a modular framework for **commonsense visualâ€“question answering (VQA)** and **visual entailment**, designed to improve **small visionâ€“language models (â‰¤250M parameters)** such as **ViLT, VisualBERT, and FLAVA**.  

The framework combines:
1. ğŸ“– **Knowledge Retrieval** â†’ Dense retrieval with a fine-tuned **ColBERTv2**  
2. ğŸ’¡ **LLM Explanations** â†’ Natural language rationales crafted by **Llama-3**, conditioned on enriched object prompts  
3. ğŸ§© **Knowledge Integration** â†’ Injecting retrieved facts + explanations into sVLMs  
4. ğŸ›¡ï¸ **Noise-Robust Training** â†’ Leveraging **Symmetric Cross Entropy (SCE)** and **Generalized Cross Entropy (GCE)**  

---

## ğŸ“Š Key Results
- ğŸš€ **+7% accuracy** on CRIC, AOKVQA, and e-SNLI-VE  
- ğŸ§  **Reduced hallucination** via retrieverâ€“explainer synergy  
- ğŸ›¡ï¸ **Noise-aware training** adds **+2.5% (CRIC)** and **+5.5% (AOKVQA)**  
- âš–ï¸ **Parameter efficiency** â†’ 250M-parameter **FLAVA** matches/exceeds **2â€“4B models** (Qwen-2 VL-2B, SmolVLM-2.5B)  

---

## ğŸ“‚ Repository Structure
```text
â”œâ”€â”€ Captioning/          # Visual captioning modules
â”œâ”€â”€ FLOPS-Calculation/   # FLOPs and efficiency computation
â”œâ”€â”€ Generation/          # LLM-based explanation generation
â”œâ”€â”€ Object-Detection/    # Object tagging and detection scripts
â”œâ”€â”€ Retrieval/           # ColBERTv2 retriever training and inference
â”œâ”€â”€ Train-Test/          # Training and evaluation scripts (CE, SCE, GCE losses)
â”œâ”€â”€ requirements.txt     # Dependencies
â””â”€â”€ README.md

```
## âš™ï¸ Installation
```bash
git clone https://github.com/beingdutta/NLKI-Lightweight-Natural-Language-Knowledge-Integration-Framework.git
cd NLKI-Lightweight-Natural-Language-Knowledge-Integration-Framework
pip install -r requirements.txt


```
## ğŸš€ Usage

#### Train with standard CE loss
python Train-Test/train.py --dataset CRIC --loss CE

#### Train with noise-robust losses (SCE / GCE)
python Train-Test/train.py --dataset AOKVQA --loss SCE


## âœ¨ Citation
```bibtex
@misc{dutta2025nlkilightweightnaturallanguage,
  title        = {NLKI: A Lightweight Natural Language Knowledge Integration Framework for Improving Small VLMs in Commonsense VQA Tasks},
  author       = {Aritra Dutta and Swapnanil Mukherjee and Deepanway Ghosal and Somak Aditya},
  year         = {2025},
  eprint       = {2508.19724},
  archivePrefix= {arXiv},
  primaryClass = {cs.CL},
  url          = {https://arxiv.org/abs/2508.19724}
}

```
## âš–ï¸ License & Data Disclaimer

This repository is released under the MIT License.

The model weights and code are provided for research purposes.

All copyrights for the training data remain with their original owners; no claim of ownership is made.